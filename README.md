[![Nextflow](https://img.shields.io/badge/nextflow%20DSL2-%E2%89%A524.04.2-23aa62.svg)](https://www.nextflow.io/)
[![run with conda](http://img.shields.io/badge/run%20with-conda-3EB049?labelColor=000000&logo=anaconda)](https://docs.conda.io/en/latest/)
[![run with docker](https://img.shields.io/badge/run%20with-docker-0db7ed?labelColor=000000&logo=docker)](https://www.docker.com/)
[![run with singularity](https://img.shields.io/badge/run%20with-singularity-1d355c.svg?labelColor=000000)](https://sylabs.io/docs/)

## Introduction

This workflow is designed to compute [quality metrics as required by BfArM](https://www.bfarm.de/SharedDocs/Downloads/DE/Forschung/modellvorhaben-genomsequenzierung/Qs-durch-GRZ.pdf?__blob=publicationFile) for **genome data centers (Genomrechenzentren, GRZs)** and serves as a **reference implementation** for all **Leistungserbringer (LEs)**.

> [!IMPORTANT]
>
> - Leistungserbringer are not required to use this specific workflow to calculate metrics. Any method that produces reasonably matching results can be used. This workflow will be used by the GRZ's to validate the reported metrics.
> - Please note that we are neither permitted nor able to provide direct support for running this QC workflow in hospitals.
> - Features such as running on pre-mapped reads are not part of the official requirements, but are offered as helpful additions for LEs when feasible.
> - We greatly appreciate collaboration and encourage contributions to help improve the workflow.

This workflow is built using [Nextflow](https://www.nextflow.io/) and processes data roughly according to the following steps:

1. Read QC and trimming ([`FastQC`](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) and [`fastp`](https://github.com/OpenGene/fastp)/[`fastplong`](https://github.com/OpenGene/fastplong))
2. Alignment using [`bwa-mem2`](https://github.com/bwa-mem2/bwa-mem2) or [`minimap2`](https://github.com/lh3/minimap2)
3. MarkDuplicates using [`Sambamba`](https://github.com/biod/sambamba) (short reads only)
4. Coverage calculation by [`mosdepth`](https://github.com/brentp/mosdepth)
5. Present QC for raw reads ([`MultiQC`](http://multiqc.info/))

Details on the coverage calculation of different library types can be found in the [documentation](docs/details.md).

For the exact command lines executed by the pipeline you may check the workflow reports automatically generated by the test pipeline on GitHub.
To access these reports, click on the title of the latest successful [pipeline run](https://github.com/BfArM-MVH/GRZ_QC_Workflow/actions/workflows/tests.yml) and download one of the `nextflow-pipeline-info` artifacts under the "Artifacts" section at the bottom of the page.
The command lines are detailed the the "Tasks" table at the bottom of the `execution_report_*.html` file.

## Setup

- Install nextflow (and dependencies)
- Make sure to have either conda, docker or singularity.
- Clone the github repository

```bash
git clone https://github.com/BfArM-MVH/GRZ_QC_Workflow.git
output_basepath="path/to/analysis/dir"
mkdir -p ${output_basepath}/grzqc_output
```

## Usage

This pipeline needs one of the following two inputs:

1. A submission base directory path with a folder structure following [GRZ submission standard](https://github.com/BfArM-MVH/grz-cli?tab=readme-ov-file#introduction). You can also check [test datasets](https://www.cmm.in.tum.de/public/grz-example-submissions/).

2. Use a csv samplesheet as input. This gives more flexibility providing optional starting points for the analysis from either reads or alignments, and you won't need a GRZ submission directory.

Here are the instructions for the case (1). For (2) please see the [documentation](docs/usage.md#samplesheet-input).

You can run the pipeline with flag `--submission_basepath`:

```bash
submission_basepath="path/to/submission/base/directory"
nextflow run main.nf \
    -profile docker \
    --outdir "${output_basepath}/grzqc_output/" \
    --submission_basepath "${submission_basepath}"
```

Depending on the resouces on your machine and your task, it is recommended to create and and run with your own config file, see [estimated resource requirements for WGS](#estimated-resource-requirements) and [nextflow documentation](https://nf-co.re/docs/usage/getting_started/configuration#custom-configuration-files).

## Prepare reference files

With the above code, the pipeline can automatically download the necessary _reference genomes_ and creates indices from them.
However, when running this pipeline multiple times on different submissions, the download and indexing steps create _unnecessary overhead_.

Therefore, **it is recommended** to run `test_GRCh37` and `test_GRCh38` profiles to set up reference files and to be sure if all the necessary images and containers are set up correctly. Thus, depending on the reference genome you will use, run the profile:

```bash
nextflow run main.nf \
    -profile test_GRCh37,docker
    --save_reference_path "your/reference/path"
```

or/and

```bash
nextflow run main.nf \
    -profile test_GRCh38,docker
    --save_reference_path "your/reference/path"
```

**Please use replace `docker` with `singularity` or `conda` depending on your system. This pipeline is able to run all profiles.**

Now, all the necessary files are saved into `your/reference/path/references`. In the next section you will see how can use these files and avoid rerunning the genome downloading and indexing steps. You can now delete test results safely:

```bash
rm -rf ${projectDir}/tests/results
```

## Use reference files

There are different options to use prepared reference files to avoid rerunning the genome downloading and bwa-mem indexing steps. The easiest way is to use `--reference_path` parameter. If you ran the both tests above successfully, you shall see references files for both GRCh38 and GRCh37 in `your/reference/path/reference`. And you can run:

```bash
nextflow run main.nf \
    -profile docker \
    --outdir "${output_basepath}/grzqc_output/" \
    --submission_basepath "${submission_basepath}" \
    --reference_path "your/reference/path/reference"
```

This approach lets the pipeline automatically use the correct reference files â€” it is helpful when you have multiple runs containing both GRCh37 and GRCh38. If you decide to skip the test runs and prepare references files by yourself, please read this [documentation](docs/usage.md#reference-files) to have the right directory structure.

Alternatively, one can prepare a config file for each genome. You can also change the lines in `conf/grzqc_GRCh37.config` and `conf/grzqc_GRCh38.config` to point the files to the correct path.

```bash
    fasta = "your/path/to/reference/GRCh37/genome.fa"
    fai   = "your/path/to/reference/GRCh37/genome.fa.fai"
    bwa   = "your/path/to/reference/GRCh37/bwamem2"
```

and run

```bash
nextflow run main.nf \
    -profile docker \
    --outdir "${output_basepath}/grzqc_output/" \
    --submission_basepath "${submission_basepath}" \
    -c conf/grzqc_GRCh37.config # or conf/grzqc_GRCh38.config
```

A more detailed description of reference files usage can be found [here](docs/usage.md#reference-files).

## Pipeline output

Output :

| Column                                      | Description                                                             |
| ------------------------------------------- | ----------------------------------------------------------------------- |
| `sampleId`                                  | Sample ID                                                               |
| `labDataName`                               | Lab data name                                                           |
| `libraryType`                               | Library type, e.g., `wes` for whole-exome sequencing                    |
| `sequenceSubtype`                           | Sequence subtype, e.g., `somatic` or `germline`                         |
| `genomicStudySubtype`                       | Genomic study subtype, e.g., `tumor+germline`                           |
| `meanDepthOfCoverage`                       | Mean depth of coverage                                                  |
| `meanDepthOfCoverageRequired`               | Mean depth of coverage required to pass QC                              |
| `percentBasesAboveQualityThreshold`         | Percent of bases passing the quality threshold                          |
| `qualityThreshold`                          | The quality threshold to pass                                           |
| `percentBasesAboveQualityThresholdRequired` | Percent of bases above the quality threshold required to pass QC        |
| `targetedRegionsAboveMinCoverage`           | Fraction of targeted regions above minimum coverage                     |
| `minCoverage`                               | Minimum coverage for target regions                                     |
| `targetedRegionsAboveMinCoverageRequired`   | Fraction of targeted regions above minimum coverage required to pass QC |
| `passedQC`                                  | `true` when QC passed, otherwise `false`                                |

For more details about the output files and reports, please refer to the [output documentation](docs/output.md).

## Thresholds

QC thresholds are read from [`thresholds.json`](https://github.com/BfArM-MVH/grz-pydantic-models/blob/main/src/grz_pydantic_models/resources/thresholds.json), which uses the values [defined by BfArM](https://www.bfarm.de/SharedDocs/Downloads/DE/Forschung/modellvorhaben-genomsequenzierung/Qs-durch-GRZ.pdf?__blob=publicationFile).

## Running the pipeline offline

Nextflow can automatically retrieve almost everything necessary to execute a pipeline from the web, including pipeline code, software dependencies, reference genomes, and remote data sources.

However, if your analysis must run on a system without _internet access_, you will need to take a few additional steps to ensure all required components are available locally. First, download everything on an internet-connected system (such as your personal computer) and then transfer the files to the offline system using your preferred method.

To set up an offline environment, you will need three key components: a functioning Nextflow installation, the pipeline assets, and the required reference genomes.

On a computer with an internet connection, to download the pipeline, run:

```bash
nf-core pipelines download BfArM-MVH/GRZ_QC_Workflow
```

Add the argument `--container-system singularity` to also fetch the singularity container(s).

Then download the necessary plugins and lace it under `${NXF_HOME}/plugins`:

```bash
nextflow plugin install nf-schema@2.1.1

```

The default reference files used in this pipeline is part of AWS iGenomes. Please follow the instructions [here](https://ewels.github.io/AWS-iGenomes/) to download:

- `s3://ngi-igenomes/igenomes/Homo_sapiens/UCSC/hg38/Sequence/WholeGenomeFasta/`
- `s3://ngi-igenomes/igenomes/Homo_sapiens/UCSC/hg19/Sequence/WholeGenomeFasta/`

For more detailed information please check ["Running offline by nf-core"](https://nf-co.re/docs/usage/getting_started/offline)

## Estimated resource requirements

Using the 466 GB `WGS_tumor+germline` test submission dataset from the
[example GRZ submissions](https://www.cmm.in.tum.de/public/grz-example-submissions),
the pipeline used the following resources:

if reference build involved:

- 618 CPU hours
- 72 GB maximum RAM (genome indexing)
- 2 TB storage (including the input files)
- Takes around 3 days

The biggest jobs were the two bwa-mem2 alignments which used 300 CPU hours each
and a maximum of 32 GB of RAM.

Without reference build:

- 600 to 620 CPU hours
- 56 GB maximum RAM
- 2 TB storage (saving alignment files)
- Takes around 2 and half days.

## Contributions and Support

**BfArM-MVH/GRZ_QC_Workflow** was originally written by Yun Wang, KÃ¼bra Narci, Travis Wrightsman, Shounak Chakraborty and Florian R. HÃ¶lzlwimmer.
